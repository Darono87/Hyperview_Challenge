{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\thesis\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1732, 150, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from loader.CSVLoader import csv_loader\n",
    "\n",
    "gt,wave = csv_loader()\n",
    "\n",
    "\n",
    "all_data = np.load(\"./experiment2/quan.npy\")\n",
    "test_data = np.load('./experiment2/quan_test.npy')\n",
    "\n",
    "#all_data = np.ma.masked_array(all_data, mask=np.isnan(all_data)).filled(0)\n",
    "#test_data = np.ma.masked_array(test_data, mask=np.isnan(test_data)).filled(0)\n",
    "\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creators.CNN3DCreator import  CNN3DNetworkParams\n",
    "from creators.CRNNCreator import CRNNNetworkParams\n",
    "from creators.ModelParams import Conv1DParams, Conv2DParams, Conv3DParams, DeepLayerParams, FlattenParams, GenericNeuralNetworkParams, RandomForestParams, RecurrentLayerParams, SVRParams\n",
    "from creators.CNN1DCreator import  CNN1DNetworkParams\n",
    "from creators.CNN2DCreator import  CNN2DNetworkParams\n",
    "from prep.HelperBlocks import pipe, split_3d_to_timeseries\n",
    "import tensorflow as tf\n",
    "from prep.MSCBlock import msc_block, msc_block1d\n",
    "\n",
    "from prep.Normlize import normalize_layers\n",
    "\n",
    "drop=0.53\n",
    "epochs=50\n",
    "optimizer = tf.keras.optimizers.Adam\n",
    "folds = 5\n",
    "\n",
    "\n",
    "params_cnn3d = CNN3DNetworkParams(\n",
    "    conv=[Conv3DParams(kernel=(10,10,1),pool_size=(10,10,1),filters=32,normalization=True,activation=\"relu\", dropout=drop),\n",
    "          Conv3DParams(kernel=(1,1,15),pool_size=(1,1,15),filters=128, normalization=True,activation=\"relu\", dropout=drop),\n",
    "          ],\n",
    "    flatten=FlattenParams(dropout=drop,normalization=True),\n",
    "    deep=[DeepLayerParams(neurons=1000,dropout=drop,normalization=True),\n",
    "          DeepLayerParams(neurons=400,dropout=drop,normalization=True)],\n",
    "    generic=GenericNeuralNetworkParams(\n",
    "        prepare_function=lambda data, is_test: pipe(data,[\n",
    "            lambda d: np.expand_dims(d, axis=-1),\n",
    "            lambda d: normalize_layers(d,not is_test)\n",
    "        ]),\n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer\n",
    "        )\n",
    ")\n",
    "\n",
    "params_cnn2d = CNN2DNetworkParams(\n",
    "    conv=[Conv2DParams(kernel=(5,5),pool_size=(2,2),filters=64,normalization=True,activation=\"relu\", dropout=drop),\n",
    "          Conv2DParams(kernel=(3,3),pool_size=(2,2),filters=512, normalization=True,activation=\"relu\", dropout=drop),\n",
    "          Conv2DParams(kernel=(2,2),pool_size=(2,2),filters=512, normalization=True,activation=\"relu\", dropout=drop),\n",
    "          ],\n",
    "    flatten=FlattenParams(dropout=drop,normalization=True),\n",
    "    deep=[DeepLayerParams(neurons=1000,dropout=drop,normalization=True),\n",
    "          DeepLayerParams(neurons=400,dropout=drop,normalization=True)],\n",
    "    generic=GenericNeuralNetworkParams(\n",
    "        prepare_function=lambda data, is_test: pipe(data,[\n",
    "            lambda d: normalize_layers(d,not is_test)]), \n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer\n",
    "        )\n",
    ")\n",
    "\n",
    "params_cnn1d = CNN1DNetworkParams(\n",
    "    conv=[Conv1DParams(kernel=10,pool_size=5,filters=500,normalization=True,activation=\"relu\", dropout=drop),\n",
    "          Conv1DParams(kernel=5,pool_size=5,filters=1500, normalization=True,activation=\"relu\", dropout=drop)\n",
    "          ],\n",
    "    deep=[DeepLayerParams(neurons=1000,dropout=drop,normalization=True),\n",
    "          DeepLayerParams(neurons=400,dropout=drop,normalization=True)],\n",
    "          flatten=FlattenParams(dropout=drop,normalization=True),\n",
    "    generic=GenericNeuralNetworkParams(\n",
    "        prepare_function=lambda data, is_test: pipe(data,[         \n",
    "            lambda d: normalize_layers(d,not is_test),\n",
    "            lambda d: np.expand_dims(d, axis=-1),\n",
    "        ]),\n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer\n",
    "        )\n",
    ")\n",
    "\n",
    "params_crnn = CRNNNetworkParams(\n",
    "    conv=[Conv3DParams(kernel=(1,10,10),pool_size=(1,10,10),filters=50,normalization=True,dropout=drop)],\n",
    "    rec=[RecurrentLayerParams(type=tf.keras.layers.LSTM,units=125,bidirectional=True,dropout=drop),\n",
    "         RecurrentLayerParams(type=tf.keras.layers.LSTM,units=125,bidirectional=True,dropout=drop)],\n",
    "    flatten=FlattenParams(dropout=drop,normalization=True),\n",
    "    deep=[DeepLayerParams(neurons=1000,dropout=drop,normalization=True),\n",
    "          DeepLayerParams(neurons=400,dropout=drop,normalization=True)],\n",
    "    generic=GenericNeuralNetworkParams(\n",
    "        prepare_function=lambda data, is_test: pipe(data,[\n",
    "            lambda d: split_3d_to_timeseries(d,15)\n",
    "        ]),\n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "params_svr = SVRParams(lambda data, is_test: normalize_layers(data,not is_test))\n",
    "params_rf = RandomForestParams(lambda data, is_test: normalize_layers(data, not is_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cnn2d_bm3d = CNN2DNetworkParams(\n",
    "    conv=[Conv2DParams(kernel=(5,5),pool_size=(2,2),filters=64,normalization=True,activation=\"relu\", dropout=drop),\n",
    "          Conv2DParams(kernel=(3,3),pool_size=(2,2),filters=512, normalization=True,activation=\"relu\", dropout=drop),\n",
    "          Conv2DParams(kernel=(2,2),pool_size=(2,2),filters=512, normalization=True,activation=\"relu\", dropout=drop),\n",
    "          ],\n",
    "    flatten=FlattenParams(dropout=drop,normalization=True),\n",
    "    deep=[DeepLayerParams(neurons=1000,dropout=drop,normalization=True),\n",
    "          DeepLayerParams(neurons=400,dropout=drop,normalization=True)],\n",
    "    generic=GenericNeuralNetworkParams(\n",
    "        prepare_function=lambda data, is_test: pipe(data,[lambda d: d]), \n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer\n",
    "        )\n",
    ")\n",
    "\n",
    "params_crnn_bm3d = CRNNNetworkParams(\n",
    "    conv=[Conv3DParams(kernel=(1,10,10),pool_size=(1,10,10),filters=50,normalization=True,dropout=drop)],\n",
    "    rec=[RecurrentLayerParams(type=tf.keras.layers.LSTM,units=125,bidirectional=True,dropout=drop),\n",
    "         RecurrentLayerParams(type=tf.keras.layers.LSTM,units=125,bidirectional=True,dropout=drop)],\n",
    "    flatten=FlattenParams(dropout=drop,normalization=True),\n",
    "    deep=[DeepLayerParams(neurons=1000,dropout=drop,normalization=True),\n",
    "          DeepLayerParams(neurons=400,dropout=drop,normalization=True)],\n",
    "    generic=GenericNeuralNetworkParams(\n",
    "        prepare_function=lambda data, is_test: pipe(data,[\n",
    "            lambda d: split_3d_to_timeseries(d,10)\n",
    "        ]),\n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svr_spec = SVRParams(lambda data, is_test: np.reshape(data,(data.shape[0],-1)))\n",
    "params_rf_spec = RandomForestParams(lambda data, is_test: np.reshape(data,(data.shape[0],-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cnn1d_quan = CNN1DNetworkParams(\n",
    "    conv=[Conv1DParams(kernel=10,pool_size=5,filters=500,normalization=True,activation=\"relu\", dropout=drop),\n",
    "          Conv1DParams(kernel=5,pool_size=5,filters=1500, normalization=True,activation=\"relu\", dropout=drop)\n",
    "          ],\n",
    "    deep=[DeepLayerParams(neurons=1000,dropout=drop,normalization=True),\n",
    "          DeepLayerParams(neurons=400,dropout=drop,normalization=True)],\n",
    "          flatten=FlattenParams(dropout=drop,normalization=True),\n",
    "    generic=GenericNeuralNetworkParams(\n",
    "        prepare_function=lambda data, is_test: data,\n",
    "        epochs=5,\n",
    "        optimizer=optimizer\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<flow.ClassicalModelFlow.ClassicalModelFlow at 0x1b58e25c3d0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ModelExperiment import ModelExperiment\n",
    "\n",
    "experiment = ModelExperiment()\n",
    "experiment.run_experiment(\n",
    "    params_vector=[params_rf_spec],\n",
    "    data=[all_data],\n",
    "    gt=[gt[\"K\"].values],\n",
    "    folds=folds,\n",
    "    test_data=[test_data]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.models[0].save_history('./experiment2/cnn1d_dwt_pH.csv')\n",
    "experiment.models[1].save_history('./experiment2/cnn2d_dwt_Mg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.get_errors_report('./experiment2/errors_dwt_pH_cnn1d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92615875 0.94365507 0.93417781 0.91160317 0.95003885]\n",
      "[0.0734853  0.05497766 0.06574003 0.08832193 0.04731133]\n",
      "[42.03165533 42.0205072  42.6650948  43.12611214 44.9043815 ]\n"
     ]
    }
   ],
   "source": [
    "print(experiment.models[0].crossval_scores)\n",
    "print(experiment.models[0].crossval_rs)\n",
    "print(experiment.models[0].mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.03476658 1.06703741 0.93329347 1.01009731 1.01159021]\n",
      "[-0.03562846 -0.06755331  0.06670624 -0.01012128 -0.01159023]\n",
      "[20.23006225 20.25107089 20.03343006 21.22519769 21.74225549]\n"
     ]
    }
   ],
   "source": [
    "print(experiment.models[1].crossval_scores)\n",
    "print(experiment.models[1].crossval_rs)\n",
    "print(experiment.models[1].mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
